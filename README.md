# ğŸ›¡ï¸ DataSentinel

A multi-agent orchestration platform for comprehensive data quality analysis using AutoGen and Snowflake.

## ğŸŒŸ Overview

DataSentinel uses a sophisticated multi-agent system to perform deep data quality analysis on Snowflake databases. It coordinates specialized AI agents through four distinct phases to investigate, profile, analyze, and report on data quality issues.

## ğŸš€ Quick Start

### Using Streamlit Web Interface (Recommended)

The easiest way to use DataSentinel is through the Streamlit web interface:

**macOS/Linux:**
```bash
./run_streamlit.sh
```
**Or manually:**
```bash
streamlit run streamlit_app.py
```

The web interface will open at `http://localhost:8501` where you can:
- Enter data quality goals interactively
- Monitor the 4-phase workflow in real-time
- View execution logs and metrics
- Download generated reports

## ğŸ“‹ Features

### Multi-Agent Architecture
- **PlannerAgent**: Creates comprehensive execution plans
- **DataAgent**: Executes SQL queries to gather evidence
- **DataProfilingAgent**: Generates statistical profiles using ydata-profiling
- **SummarizerAgent**: Synthesizes findings and identifies issues
- **ReportAgent**: Creates professional HTML reports

### 4-Phase Workflow
1. **Planning** ğŸ“‹: Break down goals into query and profiling tasks
2. **Investigation** ğŸ”: Execute tasks concurrently for fast results
3. **Analysis** ğŸ“Š: Correlate findings and identify data quality issues
4. **Reporting** ğŸ“„: Generate comprehensive HTML reports

### Key Capabilities
- âœ… Concurrent task execution for optimal performance
- âœ… Structured Pydantic outputs for type safety
- âœ… Real-time progress monitoring (Streamlit)
- âœ… Professional HTML report generation
- âœ… Statistical profiling with ydata-profiling
- âœ… Snowflake integration with connection pooling
- âœ… Comprehensive error handling and logging

## ğŸ”§ Installation

### Prerequisites
- Python 3.11 or higher
- Snowflake account with access credentials
- OpenAI API key

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd DataSentinel
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   
   Create a `.env` file in the project root:
   ```bash
   # Snowflake Connection
   SNOWFLAKE_ACCOUNT=your_account.snowflakecomputing.com
   SNOWFLAKE_USER=your_username
   SNOWFLAKE_PASSWORD=your_password
   SNOWFLAKE_WAREHOUSE=COMPUTE_WH
   SNOWFLAKE_DATABASE=YOUR_DB
   SNOWFLAKE_SCHEMA=PUBLIC
   SNOWFLAKE_ROLE=SYSADMIN
   
   # OpenAI API
   OPENAI_API_KEY=your_openai_api_key
   ```

## ğŸ“¦ Dependencies

```
# AutoGen Framework
autogen-core==0.7.5
autogen-agentchat==0.7.5
autogen-ext[openai]==0.7.5

# Snowflake Integration
snowflake-connector-python==3.18.0
snowflake-sqlalchemy==1.7.7

# Data Analysis
pandas==2.3.3
ydata-profiling==4.17.0

# Web Interface
streamlit==1.39.0

# Configuration
python-dotenv==1.1.1
```

## ğŸ¯ Usage Examples

### Example 1: Missing Values Analysis

**Streamlit UI:**
1. Open the app: `./run_streamlit.sh`
2. Enter goal: "Analyze missing values in the RIDEBOOKING table"
3. Click "Run Analysis"
4. Watch the progress through each phase


### Example 2: Data Distribution Analysis

```python
goal = "Check data distribution and identify outliers in booking amounts"
results = await orchestrator.run_analysis(goal)
```

### Example 3: Completeness Check

```python
goal = "Verify data completeness across all critical columns"
results = await orchestrator.run_analysis(goal)
```

## ğŸ“Š Workflow Phases

### Phase 1: Planning ğŸ“‹
```
User Goal â†’ PlannerAgent
  â†“
Loads schema.json
  â†“
Creates plan:
  - Query tasks for DataAgent
  - Profiling tasks for DataProfilingAgent
  - Execution sequence
  - Success criteria
```

### Phase 2: Investigation ğŸ”
```
Plan â†’ [DataAgent + DataProfilingAgent]
  â†“
Concurrent execution:
  - Multiple query tasks (async)
  - Multiple profiling tasks (async)
  â†“
Results aggregated
```

### Phase 3: Analysis ğŸ“Š
```
Combined Results â†’ SummarizerAgent
  â†“
Correlates findings
Identifies issues
Assigns severity
Creates recommendations
```

### Phase 4: Reporting ğŸ“„
```
All Results â†’ ReportAgent
  â†“
Generates HTML report with:
  - Executive summary
  - Data profiles
  - Quality assessment
  - Issues & severity
  - Recommendations
  - Visualizations
```

## ğŸ“ Project Structure

```
DataSentinel/
â”œâ”€â”€ agent/                          # Agent implementations
â”‚   â”œâ”€â”€ Orchestrator.py            # Workflow coordinator
â”‚   â”œâ”€â”€ PlannerAgent.py            # Planning agent
â”‚   â”œâ”€â”€ DataAgent.py               # Query execution agent
â”‚   â”œâ”€â”€ DataProfilingAgent.py      # Profiling agent
â”‚   â”œâ”€â”€ SummarizerAgent.py         # Analysis agent
â”‚   â”œâ”€â”€ ReportAgent.py             # Report generation agent
â”‚   â”œâ”€â”€ model/                     # Model factory
â”‚   â””â”€â”€ tool/                      # Tools and engines
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ metadata/                      # Schema definitions
â”œâ”€â”€ ge_reports/                    # Generated reports
â”œâ”€â”€ streamlit_app.py               # Web interface
â”œâ”€â”€ WorkflowRunner.py              # CLI runner
â”œâ”€â”€ run_streamlit.sh               # Streamlit launcher (Unix)
â”œâ”€â”€ run_streamlit.bat              # Streamlit launcher (Windows)
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ ARCHITECTURE.md                # Architecture documentation
â”œâ”€â”€ STREAMLIT_README.md            # Streamlit guide
â””â”€â”€ README.md                      # This file
```

## ğŸ§ª Testing

Run all tests:
```bash
./run_tests.sh
```

Run specific tests:
```bash
python -m pytest tests/agent/PlannerAgent_test.py
python -m pytest tests/agent/DataAgent_test.py
python -m pytest tests/agent/ReportAgent_test.py
```

## ğŸ“ˆ Output

DataSentinel generates several types of output:

### HTML Reports
- **Main Report**: `ge_reports/data_quality_report_*.html`
  - Executive summary
  - Detailed findings
  - Visualizations
  - Recommendations

### Profiling Reports
- **HTML Profile**: `ge_reports/*_profile_*.html`
  - Statistical analysis
  - Distribution charts
  - Correlation matrices
  - Missing value analysis

- **JSON Profile**: `ge_reports/*_profile_*.json`
  - Raw profiling data
  - Metrics and statistics

### Workflow Results
- **Results JSON**: `ge_reports/workflow_results_*.json`
  - Complete workflow output
  - All phase results
  - Timestamps

## ğŸ”’ Security

- âœ… All credentials stored in environment variables
- âœ… No hardcoded secrets
- âœ… Encrypted Snowflake connections
- âœ… Role-based access control (RBAC)
- âœ… Secure report storage

**Important:** Never commit `.env` files to version control!

## âš¡ Performance

- **Concurrent Execution**: Query and profiling tasks run in parallel using asyncio
- **Connection Pooling**: Efficient Snowflake connection management
- **Smart Sampling**: 100k row limit for profiling to balance speed and accuracy
- **Caching**: Query result caching in SnowflakeQueryEngine
- **Error Isolation**: Individual task failures don't crash the workflow

## ğŸ› Troubleshooting

### Common Issues

**Import Error:**
```
ModuleNotFoundError: No module named 'agent'
```
**Solution:** Run from project root directory

**Connection Error:**
```
Snowflake connection failed
```
**Solution:** Check `.env` file credentials and network connectivity

**Streamlit Not Found:**
```
streamlit: command not found
```
**Solution:** Install Streamlit: `pip install streamlit`

## ğŸ“– Documentation
- **[ARCHITECTURE.md](ARCHITECTURE.md)**: Detailed system architecture
- **[AutoGen Documentation](https://microsoft.github.io/autogen/)**: AutoGen framework
- **[ydata-profiling Docs](https://docs.profiling.ydata.ai/)**: Profiling library

## ğŸ› ï¸ Technology Stack

- **Python 3.11+**: Programming language
- **AutoGen 0.7.5**: Multi-agent framework
- **OpenAI GPT-4o-mini**: Language model (via gpt-5-mini)
- **Streamlit 1.39.0**: Web interface
- **ydata-profiling 4.17.0**: Statistical profiling
- **Snowflake**: Cloud data warehouse
- **Pandas 2.3.3**: Data manipulation

## ğŸš§ Roadmap

- [ ] Support for additional databases (PostgreSQL, MySQL, BigQuery)
- [ ] Custom agent plugins
- [ ] Real-time monitoring dashboard
- [ ] Scheduled workflow execution
- [ ] Multi-user collaboration features
- [ ] Advanced caching strategies
- [ ] Distributed agent execution

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

## ğŸ“„ License

[Your License Here]

## ğŸ‘¥ Authors

[Prateek Singhal]

## ğŸ™ Acknowledgments

- AutoGen team for the multi-agent framework
- ydata-profiling for statistical profiling capabilities
- Streamlit for the amazing web framework

---

**Version**: 2.1  
**Last Updated**: October 16, 2025  
**Status**: Production-Ready

**Happy Data Quality Analysis! ğŸ›¡ï¸**
